DroneSoundSeparator

ğŸš A neural network project to isolate drone sounds from noisy environments, inspired by modern audio separation techniques.
Key Improvements

    âœ… Resumable Training - Continue from saved checkpoints

    âœ… Memory-Efficient Training - Mixed precision + gradient accumulation

    âœ… Optimized Evaluation - Reduced GPU memory footprint

    âœ… Enhanced Reproducibility - Full RNG state tracking

    âœ… Dynamic Batch Handling - Adaptive memory management

Input Specifications

    Accepts multi-channel (16-channel) audio from UMA-16V2 array

    Natively supports 44.1kHz sample rate (no resampling needed)

    Processes audio chunks of any length (automatically split into 3s segments)

Project Structure

DroneSoundSeparator/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ clean_drone_16ch/   # Isolated drone audio (16-channel NPY)
â”‚   â”œâ”€â”€ noise_16ch/         # Environmental noise audio (16-channel NPY)
â”‚   â”œâ”€â”€ mixtures/           # Mixed drone+noise samples
â”‚   â””â”€â”€ metadata.csv        # Metadata for mixtures
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ explore_data.ipynb  # Data exploration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ create_dataset.py   # Script to create mixed audio dataset
â”‚   â”œâ”€â”€ data_loader.py      # Dataset and DataLoader
â”‚   â”œâ”€â”€ model.py            # U-Net separation model
â”‚   â”œâ”€â”€ train.py            # Training script
â”‚   â”œâ”€â”€ evaluate.py         # Evaluation script
â”‚   â”œâ”€â”€ demo.py             # Real-time processing demo
â”‚   â””â”€â”€ utils.py            # STFT/iSTFT, helpers, metrics
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_data/          # Sample audio files
â”‚   â”‚   â”œâ”€â”€ 20231001-TEST-44k/   # 44.1kHz test data
â”‚   â”‚   â”‚   â”œâ”€â”€ audio_chunks/    # Test audio segments
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunk_0.npy  # Clean drone audio (16ch)
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ chunk_1.npy  # Noise audio (16ch)
â”‚   â”‚   â”‚   â””â”€â”€ metadata.json    # Test data metadata
â”‚   â”œâ”€â”€ conftest.py         # Shared fixtures
â”‚   â”œâ”€â”€ test_core.py        # I/O and core logic
â”‚   â”œâ”€â”€ test_model.py       # Model tests
â”‚   â”œâ”€â”€ test_44khz.py       # 44.1kHz sample rate tests
â”‚   â”œâ”€â”€ generate_test_data.py # Test data generation script
â”‚   â”œâ”€â”€ test_perf.py        # Performance tests
â”‚   â””â”€â”€ test_edge.py        # Edge cases
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml         # Experiment configuration
â”‚
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ run1/               # Logs, checkpoints, TensorBoard
â”‚
â”œâ”€â”€ convert_wav_to_npy.py   # Audio format conversion script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ requirements-test.txt   # Testing dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md

Setup

    Install dependencies:
    bash

pip install -r requirements.txt

Convert audio files:
bash

python convert_wav_to_npy.py --src-root /path/to/raw/audio --dest-root data

Create dataset:
bash

    python src/create_dataset.py --config configs/config.yaml

Training
Basic Usage
bash

python src/train.py --config configs/config.yaml

Resume Training
bash

python src/train.py --config configs/config.yaml --resume experiments/run1/ckpt_epoch10.pt

Key Features

    40% memory reduction via mixed precision

    Configurable gradient accumulation

    Automatic batch splitting for OOM prevention

Model Architecture

U-Net Based Separator

    Input: 16-channel magnitude spectrogram

    Output: Time-frequency mask [0,1]

    Loss: SI-SDR with phase reconstruction

    5-layer encoder/decoder with skip connections

Configuration
yaml

# configs/config.yaml
training:
  use_amp: true                # Enable mixed precision
  gradient_accumulation: 4     # Accumulate over 4 batches
  max_gpu_utilization: 0.8     # Limit VRAM usage
  
checkpoints:
  save_rng_states: true        # For exact reproducibility
  save_frequency: 5            # Save every 5 epochs

Evaluation
Basic Usage
bash

python src/evaluate.py --config configs/config.yaml --checkpoint experiments/run1/best_model.pt

Advanced Options
bash

--output-dir results/       # Save per-sample metrics
--batch-size 8              # Control memory usage
--compute-sdr false         # Disable SDR for faster runs

Visualization

TensorBoard Integration:
bash

tensorboard --logdir experiments/run1/logs --bind_all

Track:

    Loss curves with smoothing

    Validation metrics by SNR

    GPU memory utilization

    Audio waveform comparisons

Testing

Run Full Suite:
bash

pytest tests/ -v --cov=src --cov-report=html

Key Tests:

    Training resumption consistency

    Memory leak detection

    44.1kHz processing fidelity

Monitoring
GPU Utilization
bash

watch -n 1 nvidia-smi

Memory Profiling
bash

python -m torch.utils.bottleneck src/train.py --config configs/config.yaml

License

MIT License - See LICENSE for details
